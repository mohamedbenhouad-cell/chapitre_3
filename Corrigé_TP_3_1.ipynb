{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFKcuGoJij+QdW3BpfWkBV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedbenhouad-cell/chapitre_3/blob/main/Corrig%C3%A9_TP_3_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Code Python pour endocer les variables qualitatives**"
      ],
      "metadata": {
        "id": "mWhLLiOCmY40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Charger le fichier Excel\n",
        "file_path = '/content/TP_3.1.xlsx'\n",
        "# Lire les données de la feuille \"Sheet1\"\n",
        "df_data = pd.read_excel(file_path, sheet_name='Sheet1')\n",
        "# Dictionnaire de codification\n",
        "codification = {\n",
        "    \"Articles de sport\": 1,\n",
        "    \"Beauté\": 2,\n",
        "    \"Électroménagers\": 3,\n",
        "    \"Électroniques\": 4,\n",
        "    \"Vêtements\": 5\n",
        "}\n",
        "# Encoder les colonnes qualitatives directement\n",
        "df_data['Catégorie_produits_achetés_dominants'] = df_data['Catégorie_produits_achetés_dominants'].map(codification)\n",
        "df_data['Catégorie_produits_consultés'] = df_data['Catégorie_produits_consultés'].map(codification)\n",
        "df_data['Catégorie_recommandée_achetée'] = df_data['Catégorie_recommandée_achetée'].map(codification)\n",
        "# Sauvegarder les données encodées dans un nouveau fichier Excel (ou écraser l'ancien fichier)\n",
        "output_file_path = 'TP_3.1_Data_encodé.xlsx'\n",
        "df_data.to_excel(output_file_path, index=False)\n",
        "print(f\"Les données encodées ont été sauvegardées dans {output_file_path}\")\n"
      ],
      "metadata": {
        "id": "K3sOH9fOmn7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.1.L’algorithme k-plus proches voisins**"
      ],
      "metadata": {
        "id": "KpFh3EfCmzQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des bibliothèques\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "# Chargement des données d'apprentissage à partir de la feuille Excel\n",
        "df_train = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Train')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_train = df_train['Y']\n",
        "# Normalisation des variables quantitatives (X2, X3, X4, X5, X7, X8, X9)\n",
        "scaler = StandardScaler()\n",
        "# Colonnes à normaliser\n",
        "quantitative_columns = ['X2', 'X3', 'X4', 'X5', 'X7', 'X8', 'X9']\n",
        "# Normalisation des données d'apprentissage\n",
        "X_train[quantitative_columns] = scaler.fit_transform(X_train[quantitative_columns])\n",
        "# Application du modèle KNN\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)  # Choix de k = 5 voisins\n",
        "knn_model.fit(X_train, y_train)  # Entraînement du modèle\n",
        "# Chargement des données de test à partir de la feuille Excel\n",
        "df_test = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Test')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des variables quantitatives pour les données de test\n",
        "X_test[quantitative_columns] = scaler.transform(X_test[quantitative_columns])\n",
        "# Prédictions sur la base de données de test\n",
        "y_pred = knn_model.predict(X_test)\n",
        "# Ajout de la colonne Y_pred avec les prédictions dans df_test\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "# Affichage des métriques d'évaluation\n",
        "print(\"\\nÉvaluation sur les données de test avec KNN :\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"F2-score:\", f2)\n"
      ],
      "metadata": {
        "id": "poS0IqWLm62t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.2.\tMachines à vecteurs de support (SVM)**"
      ],
      "metadata": {
        "id": "yzqJRRmbsBVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC  # Importation du modèle SVM\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "# Chargement des données d'apprentissage à partir de la feuille Excel\n",
        "df_train = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Train')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_train = df_train['Y']\n",
        "# Normalisation des variables quantitatives (X2, X3, X4, X5, X7, X8, X9)\n",
        "scaler = StandardScaler()\n",
        "# Colonnes à normaliser\n",
        "quantitative_columns = ['X2', 'X3', 'X4', 'X5', 'X7', 'X8', 'X9']\n",
        "# Normalisation des données d'apprentissage\n",
        "X_train[quantitative_columns] = scaler.fit_transform(X_train[quantitative_columns])\n",
        "\n",
        "# Application du modèle SVM avec un noyau linéaire\n",
        "svm_model = SVC(kernel='linear')  # Utilisation d'un SVM linéaire\n",
        "svm_model.fit(X_train, y_train)  # Entraînement du modèle\n",
        "# Chargement des données de test à partir de la feuille Excel\n",
        "df_test = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Test')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des variables quantitatives pour les données de test\n",
        "X_test[quantitative_columns] = scaler.transform(X_test[quantitative_columns])\n",
        "# Prédictions sur la base de données de test\n",
        "y_pred = svm_model.predict(X_test)\n",
        "# Ajout de la colonne Y_pred avec les prédictions dans df_test\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "# Affichage des métriques d'évaluation\n",
        "print(\"\\nÉvaluation sur les données de test avec SVM :\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"F2-score:\", f2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjTdZuX6sFYW",
        "outputId": "e3b3401d-0ffc-4b01-ba41-748f8ceb7a25"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Évaluation sur les données de test avec SVM :\n",
            "Accuracy: 0.9333333333333333\n",
            "Precision: 0.9434659090909091\n",
            "Recall: 0.9333333333333333\n",
            "F1-score: 0.935830220713073\n",
            "F2-score: 0.9336813252736705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-756261653.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train[quantitative_columns] = scaler.fit_transform(X_train[quantitative_columns])\n",
            "/tmp/ipython-input-756261653.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test[quantitative_columns] = scaler.transform(X_test[quantitative_columns])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.3.Naïve Bayes Gaussien**"
      ],
      "metadata": {
        "id": "XwdqLpHwzf3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB  # Importation du modèle Naive Bayes\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "# Chargement des données d'apprentissage à partir de la feuille Excel\n",
        "df_train = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Train')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_train = df_train['Y']\n",
        "# Normalisation des variables quantitatives (X2, X3, X4, X5, X7, X8, X9)\n",
        "scaler = StandardScaler()\n",
        "# Colonnes à normaliser\n",
        "quantitative_columns = ['X2', 'X3', 'X4', 'X5', 'X7', 'X8', 'X9']\n",
        "# Normalisation des données d'apprentissage\n",
        "X_train[quantitative_columns] = scaler.fit_transform(X_train[quantitative_columns])\n",
        "# Application du modèle Naive Bayes\n",
        "nb_model = GaussianNB()  # Utilisation de Naive Bayes\n",
        "nb_model.fit(X_train, y_train)  # Entraînement du modèle\n",
        "# Chargement des données de test à partir de la feuille Excel\n",
        "df_test = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Test')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des variables quantitatives pour les données de test\n",
        "X_test[quantitative_columns] = scaler.transform(X_test[quantitative_columns])\n",
        "# Prédictions sur la base de données de test\n",
        "y_pred = nb_model.predict(X_test)\n",
        "# Ajout de la colonne Y_pred avec les prédictions dans df_test\n",
        "df_test['Y_pred'] = y_pred\n",
        "\n",
        "# Évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "# Affichage des métriques d'évaluation\n",
        "print(\"\\nÉvaluation sur les données de test avec Naive Bayes Gaussien :\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"F2-score:\", f2)\n"
      ],
      "metadata": {
        "id": "BRU_N0-0zkfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.4.Arbres de décision**"
      ],
      "metadata": {
        "id": "MJXTXs24z_5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree  # Importation du modèle et de la fonction de visualisation\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "import matplotlib.pyplot as plt  # Pour l'affichage graphique\n",
        "# Chargement des données d'apprentissage à partir de la feuille Excel\n",
        "df_train = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Train')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_train = df_train['Y']\n",
        "# Application du modèle d'arbre de décision avec le critère Gini\n",
        "tree_model = DecisionTreeClassifier(criterion='gini', random_state=100, max_depth=4)  # Utilisation du coefficient Gini\n",
        "tree_model.fit(X_train, y_train)  # Entraînement du modèle\n",
        "# Chargement des données de test à partir de la feuille Excel\n",
        "df_test = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Test')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_test = df_test['Y']\n",
        "# Prédictions sur la base de données de test\n",
        "y_pred = tree_model.predict(X_test)\n",
        "# Ajout de la colonne Y_pred avec les prédictions dans df_test\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "# Affichage des métriques d'évaluation\n",
        "print(\"\\nÉvaluation sur les données de test avec un arbre de décision :\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"F2-score:\", f2)\n",
        "# Affichage de l'arbre de décision\n",
        "plt.figure(figsize=(20, 10))  # Taille de la figure\n",
        "plot_tree(\n",
        "    tree_model,\n",
        "    filled=True,  # Remplir les nœuds avec des couleurs\n",
        "    feature_names=X_train.columns,  # Noms des caractéristiques\n",
        "    class_names=[str(i) for i in tree_model.classes_],  # Noms des classes\n",
        "    rounded=True,  # Coins arrondis pour les boîtes\n",
        "    fontsize=10,  # Taille de la police\n",
        ")\n",
        "plt.title(\"Arbre de décision (Critère : Gini)\")  # Titre du graphique\n",
        "plt.show()  # Afficher le graphique\n"
      ],
      "metadata": {
        "id": "ANjsk6_j0Dl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.5.Forêts aléatoires**"
      ],
      "metadata": {
        "id": "BfiM42DI0W3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier  # Importation du modèle de forêts aléatoires\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "import matplotlib.pyplot as plt  # Pour l'affichage graphique\n",
        "# Chargement des données d'apprentissage à partir de la feuille Excel\n",
        "df_train = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Train')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_train = df_train['Y']\n",
        "# Application du modèle de forêts aléatoires\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=600,  # Nombre d'arbres dans la forêt\n",
        "    criterion='gini',  # Critère de division (Gini)\n",
        "    max_depth=5,  # Profondeur maximale de chaque arbre\n",
        "    random_state=500  # Pour la reproductibilité\n",
        ")\n",
        "rf_model.fit(X_train, y_train)  # Entraînement du modèle\n",
        "# Chargement des données de test à partir de la feuille Excel\n",
        "df_test = pd.read_excel('/content/TP_3.1_Data_encodé.xlsx', sheet_name='Test')\n",
        "# Sélection des variables exogènes (X1 à X9) et de la variable cible (Y)\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9']]\n",
        "y_test = df_test['Y']\n",
        "# Prédictions sur la base de données de test\n",
        "y_pred = rf_model.predict(X_test)\n",
        "# Ajout de la colonne Y_pred avec les prédictions dans df_test\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "# Affichage des métriques d'évaluation\n",
        "print(\"\\nÉvaluation sur les données de test avec des forêts aléatoires :\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"F2-score:\", f2)\n",
        "# Affichage de l'importance des caractéristiques\n",
        "importances = rf_model.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names, importances, color='skyblue')\n",
        "plt.xlabel(\"Importance des caractéristiques\")\n",
        "plt.ylabel(\"Caractéristiques\")\n",
        "plt.title(\"Importance des caractéristiques dans les forêts aléatoires\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pvv7snwZ0aru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "76rihRFTzvHd"
      }
    }
  ]
}