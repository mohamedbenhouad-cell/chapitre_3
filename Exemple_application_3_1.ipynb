{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfaPm6RwhQgFtKRHqah+wu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **3.1.\tLa régression logistique**"
      ],
      "metadata": {
        "id": "vAiJPr06ETgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "import statsmodels.api as sm\n",
        "# Chargement des données d'apprentissage à partir de la feuille Excel\n",
        "df_train = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Train')\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4']]\n",
        "y_train = df_train['Y']\n",
        "# Normalisation des données d'apprentissage (toutes les variables sont quantitatives)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# Application du modèle logistique et affichage des résultats\n",
        "X_train_sm = sm.add_constant(X_train_scaled)  # Ajout d'une constante pour l'ordonnée à l'origine\n",
        "logit_model = sm.Logit(y_train, X_train_sm)\n",
        "result = logit_model.fit()\n",
        "print(\"Résultats de l'apprentissage :\")\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "3i-8kvVREhvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement des données de test à partir de la feuille Excel\n",
        "df_test = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Test')\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des données de test\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Prédictions sur la base de données de test\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train_scaled, y_train)\n",
        "y_pred = logistic_model.predict(X_test_scaled)\n",
        "# Ajout de la colonne Y_pred avec les prédictions dans **df_test**\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Sauvegarde des résultats dans un fichier Excel\n",
        "output_path = '/content/predictions.xlsx'\n",
        "df_test.to_excel(output_path, index=False)\n",
        "print(f\"Les prédictions ont été enregistrées dans {output_path}\")\n"
      ],
      "metadata": {
        "id": "yq30cQLJDO0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "# Affichage des métriques d'évaluation\n",
        "print(\"\\nÉvaluation sur les données de test :\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"F2-score:\", f2)"
      ],
      "metadata": {
        "id": "IGrIMUgMD0h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2.\tLes k plus proches **voisins**"
      ],
      "metadata": {
        "id": "3y69q8jeE1iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des bibliothèques\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "# Chargement des données d'apprentissage à partir de la feuille Excel\n",
        "df_train = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Train')\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4']]\n",
        "y_train = df_train['Y']\n",
        "# Normalisation des données d'apprentissage (toutes les variables sont quantitatives)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# Application du modèle KNN\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)  # Choix de k = 3 voisins\n",
        "knn_model.fit(X_train_scaled, y_train)  # Entraînement du modèle\n",
        "# Chargement des données de test à partir de la feuille Excel\n",
        "df_test = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Test')\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des données de test\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Prédictions sur la base de données de test\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "# Ajout de la colonne Y_pred avec les prédictions dans df_test\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Enregistrement des résultats dans un nouveau fichier Excel\n",
        "df_test.to_excel('/content/Client_impulsif_with_predictions_knn.xlsx', sheet_name='Test', index=False)\n",
        "# Évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "# Affichage des métriques d'évaluation\n",
        "print(\"\\nÉvaluation sur les données de test avec KNN :\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"F2-score:\", f2)\n"
      ],
      "metadata": {
        "id": "5OJAVmppFjrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.3.\tMachine à vecteurs de support (SVM)**"
      ],
      "metadata": {
        "id": "UncWcAQGGgfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code python\n",
        "# Importation des bibliothèques\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "# Chargement et préparation des données d'entraînement\n",
        "df_train = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Train')\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4']]\n",
        "y_train = df_train['Y']\n",
        "# Standardisation des données d'entraînement\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# Initialisation du modèle SVM\n",
        "modele_svm = SVC(kernel='linear')  # Vous pouvez ajuster les paramètres kernel et C\n",
        "# Entraînement du modèle\n",
        "modele_svm.fit(X_train_scaled, y_train)\n",
        "# Chargement et préparation des données de test\n",
        "df_test = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Test')\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des données de test\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Prédictions\n",
        "y_pred = modele_svm.predict(X_test_scaled)\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Sauvegarde des prédictions dans un fichier Excel\n",
        "df_test.to_excel('/content/svm.xlsx', sheet_name='Test', index=False)\n",
        "# Calcul et affichage des métriques d'évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "print(\"\\nÉvaluation sur les données de test avec SVM :\")\n",
        "print(\"Exactitude (Accuracy) :\", accuracy)\n",
        "print(\"Précision (Precision) :\", precision)\n",
        "print(\"Rappel (Recall) :\", recall)\n",
        "print(\"Score F1 :\", f1)\n",
        "print(\"Score F2 :\", f2)\n"
      ],
      "metadata": {
        "id": "tYrbHUQqGi3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **classification SVM avec noyau polynomial**"
      ],
      "metadata": {
        "id": "XFwJXnXfTOLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "# Chargement et préparation des données d'entraînement\n",
        "df_train = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Train')\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4']]\n",
        "y_train = df_train['Y']\n",
        "# Standardisation des données d'entraînement\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# Initialisation du modèle SVM avec un noyau polynomial\n",
        "modele_svm = SVC(kernel='poly', degree=2, C=1.0, gamma='auto')  # Ajustez degree, C, gamma selon vos besoins\n",
        "# Entraînement du modèle\n",
        "modele_svm.fit(X_train_scaled, y_train)\n",
        "# Chargement et préparation des données de test\n",
        "df_test = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Test')\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des données de test\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Prédictions sur les données de test\n",
        "y_pred = modele_svm.predict(X_test_scaled)\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Sauvegarde des prédictions dans un fichier Excel\n",
        "df_test.to_excel('/content/svm_polynomial.xlsx', sheet_name='Test', index=False)\n",
        "# Calcul et affichage des métriques d'évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "print(\"\\nÉvaluation sur les données de test avec SVM (Noyau Polynomial) :\")\n",
        "print(\"Exactitude (Accuracy) :\", accuracy)\n",
        "print(\"Précision (Precision) :\", precision)\n",
        "print(\"Rappel (Recall) :\", recall)\n",
        "print(\"Score F1 :\", f1)\n",
        "print(\"Score F2 :\", f2)\n"
      ],
      "metadata": {
        "id": "q4gxxjbsTdEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.4.Naïve Bayes**"
      ],
      "metadata": {
        "id": "Yl92jnsVT-P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code Python\n",
        "# Importation des bibliothèques\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "# Chargement et préparation des données d'entraînement\n",
        "df_train = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Train')\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4']]\n",
        "y_train = df_train['Y']\n",
        "# Modèles Naïve Bayes pour chaque type de variable\n",
        "model_gaussian = GaussianNB()    # Pour les variables continues (X2, X3, X4)\n",
        "model_bernoulli = BernoulliNB()  # Pour la classification binaire (Y)\n",
        "# Entraînement des modèles\n",
        "model_gaussian.fit(X_train[['X2', 'X3', 'X4']], y_train)  # Variables continues\n",
        "model_bernoulli.fit(X_train[['X1']], y_train)             # Variable de comptage (X1)\n",
        "# Chargement et préparation des données de test\n",
        "df_test = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Test')\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4']]\n",
        "y_test = df_test['Y']\n",
        "# Prédictions avec les modèles hybrides\n",
        "pred_gaussian = model_gaussian.predict(X_test[['X2', 'X3', 'X4']])  # Prédictions pour les variables continues\n",
        "pred_bernoulli = model_bernoulli.predict(X_test[['X1']])            # Prédictions pour la variable de comptage\n",
        "# Combinaison des prédictions (par exemple, en utilisant une logique de vote majoritaire)\n",
        "import numpy as np\n",
        "pred_combined = np.where((pred_gaussian + pred_bernoulli) >= 1, 1, 0)  # Si au moins un modèle prédit 1, on classe comme 1\n",
        "# Sauvegarde des prédictions dans un fichier Excel\n",
        "df_test['y_pred'] = pred_combined\n",
        "df_test.to_excel('/content/Client_impulsif_avec_predictions_naive_bayes_hybride.xlsx', sheet_name='Test', index=False)\n",
        "# Calcul et affichage des métriques d'évaluation\n",
        "accuracy = accuracy_score(y_test, pred_combined)\n",
        "precision = precision_score(y_test, pred_combined, average='weighted')\n",
        "recall = recall_score(y_test, pred_combined, average='weighted')\n",
        "f1 = f1_score(y_test, pred_combined, average='weighted')\n",
        "fbeta = fbeta_score(y_test, pred_combined, beta=1, average='weighted')\n",
        "f2 = fbeta_score(y_test, pred_combined, beta=2, average='weighted')\n",
        "print(\"Évaluation du modèle hybride Naïve Bayes :\")\n",
        "print(f\"Exactitude (Accuracy) : {accuracy:.4f}\")\n",
        "print(f\"Précision : {precision:.4f}\")\n",
        "print(f\"Rappel (Recall) : {recall:.4f}\")\n",
        "print(f\"F1-Score : {f1:.4f}\")\n",
        "print(f\"F-Beta Score (beta=1) : {fbeta:.4f}\")\n",
        "print(f\"F2-Score (beta=2) : {f2:.4f}\")\n"
      ],
      "metadata": {
        "id": "maMih33JUCrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}