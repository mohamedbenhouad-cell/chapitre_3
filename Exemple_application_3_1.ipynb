{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPAXF46ykz1S1QjiVepPVA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **3.1.\tLa régression logistique**"
      ],
      "metadata": {
        "id": "vAiJPr06ETgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "import statsmodels.api as sm\n",
        "# Chargement des données d'apprentissage à partir de la feuille Excel\n",
        "df_train = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Train')\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4']]\n",
        "y_train = df_train['Y']\n",
        "# Normalisation des données d'apprentissage (toutes les variables sont quantitatives)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# Application du modèle logistique et affichage des résultats\n",
        "X_train_sm = sm.add_constant(X_train_scaled)  # Ajout d'une constante pour l'ordonnée à l'origine\n",
        "logit_model = sm.Logit(y_train, X_train_sm)\n",
        "result = logit_model.fit()\n",
        "print(\"Résultats de l'apprentissage :\")\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "3i-8kvVREhvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement des données de test à partir de la feuille Excel\n",
        "df_test = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Test')\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des données de test\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Prédictions sur la base de données de test\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train_scaled, y_train)\n",
        "y_pred = logistic_model.predict(X_test_scaled)\n",
        "# Ajout de la colonne Y_pred avec les prédictions dans **df_test**\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Sauvegarde des résultats dans un fichier Excel\n",
        "output_path = '/content/predictions.xlsx'\n",
        "df_test.to_excel(output_path, index=False)\n",
        "print(f\"Les prédictions ont été enregistrées dans {output_path}\")\n"
      ],
      "metadata": {
        "id": "yq30cQLJDO0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "# Affichage des métriques d'évaluation\n",
        "print(\"\\nÉvaluation sur les données de test :\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"F2-score:\", f2)"
      ],
      "metadata": {
        "id": "IGrIMUgMD0h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2.\tLes k plus proches **voisins**"
      ],
      "metadata": {
        "id": "3y69q8jeE1iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des bibliothèques\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "# Chargement des données d'apprentissage à partir de la feuille Excel\n",
        "df_train = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Train')\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4']]\n",
        "y_train = df_train['Y']\n",
        "# Normalisation des données d'apprentissage (toutes les variables sont quantitatives)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# Application du modèle KNN\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)  # Choix de k = 3 voisins\n",
        "knn_model.fit(X_train_scaled, y_train)  # Entraînement du modèle\n",
        "# Chargement des données de test à partir de la feuille Excel\n",
        "df_test = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Test')\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des données de test\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Prédictions sur la base de données de test\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "# Ajout de la colonne Y_pred avec les prédictions dans df_test\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Enregistrement des résultats dans un nouveau fichier Excel\n",
        "df_test.to_excel('/content/Client_impulsif_with_predictions_knn.xlsx', sheet_name='Test', index=False)\n",
        "# Évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "# Affichage des métriques d'évaluation\n",
        "print(\"\\nÉvaluation sur les données de test avec KNN :\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"F2-score:\", f2)\n"
      ],
      "metadata": {
        "id": "5OJAVmppFjrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3.\tMachine à vecteurs de support (SVM)"
      ],
      "metadata": {
        "id": "UncWcAQGGgfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code python\n",
        "# Importation des bibliothèques\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "# Chargement et préparation des données d'entraînement\n",
        "df_train = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Train')\n",
        "X_train = df_train[['X1', 'X2', 'X3', 'X4']]\n",
        "y_train = df_train['Y']\n",
        "# Standardisation des données d'entraînement\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# Initialisation du modèle SVM\n",
        "modele_svm = SVC(kernel='linear')  # Vous pouvez ajuster les paramètres kernel et C\n",
        "# Entraînement du modèle\n",
        "modele_svm.fit(X_train_scaled, y_train)\n",
        "# Chargement et préparation des données de test\n",
        "df_test = pd.read_excel('/content/exemple_3.1.xlsx', sheet_name='Test')\n",
        "X_test = df_test[['X1', 'X2', 'X3', 'X4']]\n",
        "y_test = df_test['Y']\n",
        "# Normalisation des données de test\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Prédictions\n",
        "y_pred = modele_svm.predict(X_test_scaled)\n",
        "df_test['Y_pred'] = y_pred\n",
        "# Sauvegarde des prédictions dans un fichier Excel\n",
        "df_test.to_excel('/content/svm.xlsx', sheet_name='Test', index=False)\n",
        "# Calcul et affichage des métriques d'évaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2, average='weighted')\n",
        "print(\"\\nÉvaluation sur les données de test avec SVM :\")\n",
        "print(\"Exactitude (Accuracy) :\", accuracy)\n",
        "print(\"Précision (Precision) :\", precision)\n",
        "print(\"Rappel (Recall) :\", recall)\n",
        "print(\"Score F1 :\", f1)\n",
        "print(\"Score F2 :\", f2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYrbHUQqGi3C",
        "outputId": "93b5884e-8924-4ea7-e095-2f7f96393023"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Évaluation sur les données de test avec SVM :\n",
            "Exactitude (Accuracy) : 0.9\n",
            "Précision (Precision) : 0.9142857142857143\n",
            "Rappel (Recall) : 0.9\n",
            "Score F1 : 0.8967032967032967\n",
            "Score F2 : 0.896434634974533\n"
          ]
        }
      ]
    }
  ]
}